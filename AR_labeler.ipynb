{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Released Video Resource\n",
      "Saving Video\n",
      "Time for Application of Augmented Layer\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'00:00:29'"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Import of libraries\n",
    "import numpy as np\n",
    "import cv2\n",
    "from IPython.display import clear_output\n",
    "import time\n",
    "\n",
    "# Starting message\n",
    "print('Initial Configuration')\n",
    "\n",
    "# Import of reference frame, augmented layer and mask\n",
    "ref_frame = cv2.imread(\"ReferenceFrame.png\")\n",
    "agm_layer = cv2.imread(\"AugmentedLayer.png\")\n",
    "agm_mask = cv2.imread(\"AugmentedLayerMask.png\")\n",
    "\n",
    "# Shape of reference frame (And in generale of the video)\n",
    "h, w = ref_frame.shape[:2]\n",
    "\n",
    "# Reshaping of augmented layer and its mask\n",
    "layer_reshaped = np.copy(agm_layer[0:h,0:w])\n",
    "mask_reshaped = np.copy(agm_mask[0:h,0:w])\n",
    "\n",
    "# Separation of the masks\n",
    "mask_bottom = np.zeros(ref_frame.shape, np.uint8)\n",
    "mask_bottom[int(h/2):h, 0:w] = mask_reshaped[int(h/2):h, 0:w]\n",
    "mask_top = np.zeros(ref_frame.shape, np.uint8)\n",
    "mask_top[0:int(h/2), 0:w] = mask_reshaped[0:int(h/2), 0:w]\n",
    "\n",
    "# Create SURF object. You can specify params here or later.\n",
    "# Here we set Hessian Threshold (major the value, less kp are saved)\n",
    "hess_thresh = 4500\n",
    "surf = cv2.xfeatures2d.SURF_create(hess_thresh)\n",
    "kp_ref, des_ref = surf.detectAndCompute(ref_frame,None)\n",
    "\n",
    "# Import Video\n",
    "orig_video = cv2.VideoCapture(\"Multiple View.avi\")\n",
    "\n",
    "# Set video writer\n",
    "fourcc = cv2.VideoWriter_fourcc(*'DIVX')\n",
    "fps = orig_video.get(cv2.CAP_PROP_FPS)\n",
    "# N.B. we need to specify the correct width and height of the frames \n",
    "out = cv2.VideoWriter('AR_MultipleView.avi', fourcc, fps, (w,  h))\n",
    "\n",
    "# Barycentre calcolous for bottom mask placing\n",
    "# Bottom\n",
    "gray_mask=cv2.cvtColor(mask_bottom, cv2.COLOR_BGR2GRAY)\n",
    "returned ,binarized = cv2.threshold(gray_mask,127,255,0)\n",
    "Mom = cv2.moments(binarized)\n",
    "cX = (Mom[\"m10\"] / Mom[\"m00\"])\n",
    "cY = (Mom[\"m01\"] / Mom[\"m00\"])\n",
    "centerBottom = (int(cX),int(cY))\n",
    "# Top\n",
    "gray_mask=cv2.cvtColor(mask_top, cv2.COLOR_BGR2GRAY)\n",
    "returned ,binarized = cv2.threshold(gray_mask,127,255,0)\n",
    "Mom = cv2.moments(binarized)\n",
    "cX = (Mom[\"m10\"] / Mom[\"m00\"])\n",
    "cY = (Mom[\"m01\"] / Mom[\"m00\"])\n",
    "centerTop = (int(cX),int(cY))\n",
    "\n",
    "# Message of starting computing\n",
    "#clear_output(wait=True)\n",
    "print('Computing Video')\n",
    "\n",
    "# Start Time\n",
    "start_time = time.time()\n",
    "    \n",
    "while(orig_video.isOpened()):\n",
    "    # Capture frame\n",
    "    ret, frame = orig_video.read()\n",
    "    if not ret or frame is None:\n",
    "        # Clear cell output when new frame is available\n",
    "        clear_output(wait=True)\n",
    "        # Release the Video if ret is false\n",
    "        orig_video.release()\n",
    "        print(\"Released Video Resource\")\n",
    "        out.release()\n",
    "        print(\"Saving Video\")\n",
    "        # Break exit the for loops\n",
    "        break\n",
    "    \n",
    "    # SURF detection of current frame\n",
    "    kp_frame, des_frame = surf.detectAndCompute(frame,None)\n",
    "\n",
    "    # Initializing the matching algorithm\n",
    "    FLANN_INDEX_KDTREE = 1\n",
    "    index_params = dict(algorithm = FLANN_INDEX_KDTREE, trees = 5)\n",
    "    search_params = dict(checks = 50)\n",
    "    flann = cv2.FlannBasedMatcher(index_params, search_params)\n",
    "    # Matching the descriptors\n",
    "    matches = flann.knnMatch(des_ref,des_frame,k=2)\n",
    "    # Keeping only good matches as per Lowe's ratio test\n",
    "    good = []\n",
    "    for m,n in matches:\n",
    "        if m.distance < 0.7*n.distance:\n",
    "            good.append(m)\n",
    "\n",
    "    # Checking if we found the object\n",
    "    MIN_MATCH_COUNT = 10\n",
    "    if len(good)>MIN_MATCH_COUNT:\n",
    "        src_pts = np.float32([ kp_ref[m.queryIdx].pt for m in good ]).reshape(-1,1,2)\n",
    "        dst_pts = np.float32([ kp_frame[m.trainIdx].pt for m in good ]).reshape(-1,1,2)\n",
    "    \n",
    "        # Getting the coordinates of the corners of our query object in the train image\n",
    "        H_mat, mask = cv2.findHomography(src_pts, dst_pts, cv2.RANSAC, 5.0)\n",
    "        H_inv = np.linalg.inv(H_mat)\n",
    "        \n",
    "        # Warping of the mask\n",
    "        warped_mask = cv2.warpPerspective(mask_reshaped, H_mat, (w, h))\n",
    "        # Boolean total mask\n",
    "        warped_mask_bool = np.equal(warped_mask, 255)\n",
    "        \n",
    "        # Dewarping of the frame to apply the augmented layer\n",
    "        dewarped_frame = cv2.warpPerspective(frame, H_inv, (w, h))\n",
    "        agm_frame = cv2.seamlessClone(layer_reshaped, dewarped_frame, mask_bottom, centerBottom, 0)\n",
    "        agm_frame = cv2.seamlessClone(layer_reshaped, agm_frame, mask_top, centerTop, 0)\n",
    "        \n",
    "        # Rewarping of the agm frame\n",
    "        warped_agm_frame = cv2.warpPerspective(agm_frame, H_mat, (w, h))\n",
    "\n",
    "        # Restore previous values of the train images where the mask is black\n",
    "        frame[warped_mask_bool] = warped_agm_frame[warped_mask_bool]\n",
    "        \n",
    "        # Write the output frame\n",
    "        out.write(frame)\n",
    "\n",
    "    else:\n",
    "        print( \"Not enough matches are found - {}/{}\".format(len(good), MIN_MATCH_COUNT) )\n",
    "            \n",
    "elapsed_time = time.time() - start_time\n",
    "print('Time for Application of Augmented Layer')\n",
    "time.strftime(\"%H:%M:%S\", time.gmtime(elapsed_time))\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
